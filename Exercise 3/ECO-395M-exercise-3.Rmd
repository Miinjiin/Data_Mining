---
title: "ECO 395M exercise 3"
author: "Minjin Kang, Paul Park, Phillip An"
date: "2023-02-27"
output: md_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(dplyr)
library(rsample)  
library(caret)
library(modelr)
library(lubridate)
library(randomForest)
library(gbm)
library(pdp)
library(knitr)
library(scales)
library(ggmap)
library(kableExtra)

```

## 1) What causes what?


**Question 1 Why I can't just get data from a few different cities and run the regression of "crime" on "police" to understand how more cops in the streets affect crime?**

Running regression is not enough to find causation. The number of cops can't explain all about the crime rate. There can be other factors(confounders) affecting the crime rate, for example, drug/alcohol regulations, access to weapons, the criminal justice system, income inequality, and population density. Plus, there exist inherent differences for each city, and there can be a selection bias problem from collecting different cities in the sample. If there's a selection bias problem, we can't generalize the result of the regression. 


**Question 2 How UPenn able to isolate this effect?**

UPenn added instrumental variable 'High Alert' and 'Midday Ridership'. In a High Alert day, more cops will be on the street and shops and less people will be in public who can be targeted as victim. If we see the table, controlling High Alert, total daily crime lowered by 7. Mid day Ridership is dummy variable controlling METRO ridership. Including Mid day Ridership, there's still a negative relationship between high alert and crime, total daily crime lowered by 6. 


**Question 3 Why did they have to control for Metro ridership?** 

To get a true effect of police presence on crime rate in D.C., the researchers decided to control Metro ridership, as adding this IV variable can control the probability that the crime rate goes up/down from the fact that more/less people on the street. We can mitigate the potential biases caused by METRO ridership usage and can obtain clearer estimate of causal effect of police presence on crime rate. 


**Question 4 What was that trying to capture?**

The first column of the table is about linear model using robust regression with the dependent variable daily total number of crimes in D.C. Here, on top of two instrumental variables 'High Alert' and 'Midday ridership', researchers added 'District 1' dummy variable, which demonstrates that crime happened in the first policy district area. Interaction term 'High Alert x District 1''s coefficient -2.6 illustrates the differential effect of the high alert on the first policy district area compared to non-first policy district area. Holding all else fixed, this interaction variable is associated with 2.6 less total daily crime. Interaction term 'High Alert x Other Districts''s coefficient -0.57 implies the differential effect of the high alert on the other districts compared to non-other districts. Holding all else fixed, this interaction variable is associated with 0.57 less total daily crime. The coefficient of 'Midday ridership' means, with the METRO ridership control, it is expected to have 6 less total daily crime.  


## 2) Tree modeling: dengue cases

\newline

#### Classification and Regression Trees (CART) to predict dengue cases

After dropping missing values from `dengue.csv`, I created base model regressing total_cases for all other variables, and with `rpart()` function, plotted the result tree. This is un-pruned tree which allows tree to grow its maximum size, includes all possible splits in the training data.

```{r problem 2.CART.1, message=FALSE, echo=FALSE, warning=FALSE}
# import data set
dengue=read.csv('Data/dengue.csv')

# find the count of missing values
a=sum(is.na(dengue))
dengue=na.omit(dengue)
b=sum(is.na(dengue))

# categorize the data and store it as levels (as city and season is character)
dengue$city = factor(dengue$city)
dengue$season = factor(dengue$season)

# split into training and testing set
dengue_split = initial_split(dengue, prop = 0.8)
dengue_train = training(dengue_split)
dengue_test = testing(dengue_split)

# make base model
dengue_tree_CART=rpart(total_cases ~ . , data=dengue_train, control=rpart.control(cp=0.002,minsplit=30))

# the various summaries of the tree
# print(dengue_tree_CART) # the structure
# summary(dengue_tree_CART)  # more detail on the splits

# plot the decision tree 
rpart.plot(dengue_tree_CART, digits=-5, type=4, extra=1)


```

To perform cross-validation, I used prune function given during the class and adopted in my base model to evaluate performance.

```{r problem 2.CART.2, message=FALSE, echo=FALSE, warning=FALSE}

# use the code in the tree slide 
prune_1se = function(my_tree) {
  require(rpart)
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

# prune with the tree model we made
dengue_tree_prune1se = prune_1se(dengue_tree_CART)

# plot the tree 
rpart.plot(dengue_tree_prune1se, digits=4, type=4, extra=1, fallen.leaves = TRUE)
```

\newline

Out-of-sample RMSEs for un-pruned CART and pruned CART is, 

```{r problem 2.CART.3, message=FALSE, echo=FALSE, warning=FALSE}
# check the rmse
rmse_CART_nonprune=rmse(dengue_tree_CART,dengue_test)
rmse_CART_prune=rmse(dengue_tree_prune1se,dengue_test)

# print the rmse
rmse_CART_nonprune
rmse_CART_prune
```

Result shows pruned CART gives a little bit higher RMSE compared to un-pruned CART. This is due to the fact that pruned CART has higher bias and lower variance as it is less flexible then un-pruned CART. 

\newline\newline

#### Random Forests to predict dengue cases

I created base model regressing total_cases for all other variables and plotted a variable importance plot.

```{r problem 2.Random_forest.1, message=FALSE, echo=FALSE, warning=FALSE}

# fit a tree for random forest
dengue_tree_RF = randomForest(total_cases ~ . , data=dengue_train, important=TRUE)

# performance as a function of iteration number
# plot(dengue_tree_RF)

# a variable importance plot: how much SSE decreases from including each var
varImpPlot(dengue_tree_RF)

```

Will use this plot later to pick the variable for partial dependence plot. 

Cross validation is not strictly needed for building a random forest model, as random forest combines multiple decision trees. The randomness of random forest eliminates need for cross validation. 

\newline

Out-of-sample RMSEs for random forests is, 

```{r problem 2.Random_forest.2, message=FALSE, echo=FALSE, warning=FALSE}

# check the rmse
rmse_RF=rmse(dengue_tree_RF,dengue_test)

# print the rmse
rmse_RF

```

\newline\newline

#### Gradient Boosted trees to predict dengue cases

After fitting tree for gradient boosted trees model, for cross validation, I added `cv.folds()` in `gbm` package. I searched common choice for the number of folds is between 5 and 10, so I chose 8. I plotted error curve, which is deviance plot. 

```{r problem 2.Gradient_boosted.1, message=FALSE, echo=FALSE, warning=FALSE}

# fit a tree for gradient boosted trees
dengue_tree_Boost= gbm(total_cases ~ . ,distribution='gaussian', data=dengue_train,interaction.depth=4, n.trees=500, shrinkage=.05, cv.folds = 8)
  
# plot for gradient boosting 
# plot(dengue_tree_Boost)

# Look at error curve -- stops decreasing much after ~300
gbm.perf(dengue_tree_Boost)
```

The green line is our cross validated error. 
The x-axis of error curve is number of iterations and y-axis of error curve is deviance of the model, which measures goodness of the fit.
The blue dashed line is the best number of iteration minimizing error. 

\newline

Out-of-sample RMSEs for Gradient boosted tree is, 

```{r problem 2.Gradient_boosted.2, message=FALSE, echo=FALSE, warning=FALSE}

# check the rmse
rmse_Boost=rmse(dengue_tree_Boost,dengue_test)

# print the rmse
rmse_Boost

```

\newline\newline

##### Checking model performance with out-of-sample RMSEs for each models

```{r problem 2.RMSE_table, message=FALSE, echo=FALSE, warning=FALSE}

first_col= c("Tree","Pruned Tree","Random Forest","Gradient Boosting")
second_col= c(rmse_CART_nonprune,rmse_CART_prune,rmse_RF,rmse_Boost)

df = data.frame(first_col, second_col)

knitr::kable(df,col.names = c("",""))%>%
  kable_styling(bootstrap_options = "striped", full_width = F)

```
We can check that the Random Forest is the best performance on the testing data.

\newline\newline

#### Partial dependence plots

With selected best performance model, Random Forest, we will plot the partial dependence plots to isolate the partial effect of specific features on the outcome. Will make three partial dependence plots about `specific_humidity`, `precipitation_amt` and our group's choice `min_air_temp_k`. This variable was chosen from a variable importance plot made from Random Forest part.

##### `specific_humidity`
```{r problem 2.partial_plots.1, message=FALSE, echo=FALSE, warning=FALSE}

partialPlot(dengue_tree_RF, dengue_test, 'specific_humidity', las=1)

```

##### `precipitation_amt`
```{r problem 2.partial_plots.2, message=FALSE, echo=FALSE, warning=FALSE}

partialPlot(dengue_tree_RF, dengue_test, 'precipitation_amt', las=1)

```


##### `min_air_temp_k`
```{r problem 2.partial_plots.3, message=FALSE, echo=FALSE, warning=FALSE}

partialPlot(dengue_tree_RF, dengue_test, 'min_air_temp_k', las=1)

```

Plots shows increasing graph, we can interpret this these features has a positive effect on predicted outcome. 

\newline\newline

## 3) Predictive model building: green certification


1) Overview
This question attempts to build the best predictive model for revenue per square foot per calender year and to use this model to possibly quantify the average change in rental income per square foot associated with green certification, holding other features of the building constant. 


2) Modeling
First, I created a new variable called "revenue" by multiplying Rent and leasing_rate
 Next, I split the data into train and test set

```{r problem 3.1, message=FALSE, echo=FALSE, warning=FALSE}
#Open the data
green = read.csv('Data/greenbuildings.csv')

##First, I created a new variable called "revenue" by multiplying Rent and leasing_rate

green$revenue = green$Rent * green$leasing_rate

  
## Next, I split the data into train and test set
green_split = initial_split(green, prop = 0.8)
green_train = training(green_split)
green_test = testing(green_split)

```

We started out by fitting a linear regression model to predict revenue that included every variable in the data set as predictors.  
We took out Rent and leasing_rate as they are already taken into account as revenue.
We also chose to take out LEED and Energystar and collapsed them into a single "green certified" category.


```{r problem 3.2, message=FALSE, echo=FALSE, warning=FALSE}
lm_green1 = lm(revenue ~ . - Rent - leasing_rate - CS_PropertyID - LEED - Energystar, data = green_train)


```


We improved our linear regression model by adding interactions between Gas_Costs, Electricity Costs with possible sources of the costs. Specifically, we figured that gas and electricity costs are associated with number of heating/cooling degree days, precipitation, city market rent, stories, age, amenities, renovation status by correlation tests.

```{r problem 3.3, message=FALSE, echo=FALSE, warning=FALSE}

# creating a new improved linear regression model
lm_green_improved = lm(revenue ~ . - Rent - leasing_rate - CS_PropertyID - LEED - Energystar + Gas_Costs:total_dd_07 + Gas_Costs:Precipitation + Gas_Costs:amenities + Gas_Costs:City_Market_Rent +  Gas_Costs:stories +  Electricity_Costs:renovated + Electricity_Costs:total_dd_07 + Electricity_Costs:Precipitation + Electricity_Costs:Gas_Costs + Electricity_Costs:stories + Electricity_Costs:age + Electricity_Costs:City_Market_Rent + Electricity_Costs:amenities, data = green_train)

```

We then created a CART model with basic independent variables

```{r problem 3.4, message=FALSE, echo=FALSE, warning=FALSE}

green_tree = rpart(revenue ~ . - CS_PropertyID - Rent - leasing_rate - LEED - Energystar, data=green_train, control = rpart.control(cp = 0.002, minsplit = 30))


```

Next, we built a pruned tree model

```{r problem 3.5, message=FALSE, echo=FALSE, warning=FALSE}


prune_1se = function(my_tree) {
  require(rpart)
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

pruned_green_tree = prune_1se(green_tree)

```

We then drew tree plots for the simple tree model and the pruned tree model.

```{r problem 3.6, message=FALSE, echo=FALSE, warning=FALSE}

rpart.plot(green_tree, type=4, extra=1)
rpart.plot(pruned_green_tree, type=4, extra=1)

```


We used random forest and boosting and created more models for comparison

We tried the random forest model and the gradient-boosted model with the interactions I used earlier, but the tree models without them give me the lowest rmse model.


```{r problem 3.7, message=FALSE, echo=FALSE, warning=FALSE}

#Random forest
random_forest_green <- randomForest(revenue~.- CS_PropertyID - Rent - leasing_rate - LEED - Energystar, data = green_train, proximity =TRUE, na.action = na.omit)

#boosting
green_boost = gbm(revenue ~ . - CS_PropertyID - Rent - leasing_rate - LEED - Energystar, data = green_train, interaction.depth=10, n.trees=500, shrinkage=.2, cv.folds = 10)

```

We then drew a variable importance plot of random forest model. The plot shows that City_Market_Rent, Size, and age contribute the most to our prediction. 

```{r problem 3.8, message=FALSE, echo=FALSE, warning=FALSE}

vi = varImpPlot(random_forest_green, type=2)

```

3) Conclusion

We fit linear models, tree models, random forests models and boosted random forests models. As we develop more sophisticated models, we find that the predictive power of the models get better and better. However, testing on the test data set, based on the out-of-sample rmse values, we find that the random forest model perform the best above all.

```{r problem 3.9, message=FALSE, echo=FALSE, warning=FALSE}

###Testing on test dataset
rmse_outcome = data.frame(
  Model = c("Linear model","Improved linear model",
            "Tree model","Pruned tree model","Random forest model","Boosted model"),
  RMSE = c(rmse(lm_green1, green_test),
           rmse(lm_green_improved, green_test),
           rmse(green_tree, green_test),
           rmse(pruned_green_tree, green_test),
           rmse(random_forest_green, green_test),
           rmse(green_boost, green_test))
)

kable(rmse_outcome)
```


## 4) Predictive model building: California housing 


```{r problem 4, message=FALSE, echo=FALSE, warning=FALSE}
cahousing=read.csv('Data/CAhousing.csv')

cahousing_split = initial_split(cahousing, prop = 0.8)
cahousing_train = training(cahousing_split)
cahousing_test = testing(cahousing_split)


#Prediction using CART / fitting a single tree
cahousing.tree = rpart(medianHouseValue ~ ., data=cahousing_train,
                  control = rpart.control(cp = 0.002, minsplit=30))

  #Prune the tree at which level CV error is within 1 std err of the minimum
prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

  #Prune our tree at the 1se complexity level
cahousing.tree_prune = prune_1se(cahousing.tree)

  #RMSE of CART
rmse_CART = rmse(cahousing.tree_prune, cahousing_test)

#Prediction using Random Forest
cahousing.forest = randomForest(medianHouseValue ~ ., data=cahousing_train, importance = TRUE)

##Prediction using Gradient-Boosted Trees
cahousing.gbm = gbm(medianHouseValue ~ ., data=cahousing_train, 
               interaction.depth=2, n.trees=500, shrinkage=.05)


#compare RMSE among the three models
rmse_cart = modelr::rmse(cahousing.tree_prune, cahousing_test)
rmse_rf = modelr::rmse(cahousing.forest, cahousing_test)
rmse_gbm = modelr::rmse(cahousing.gbm, cahousing_test)

rmse_cart
rmse_rf
rmse_gbm

# Create a comparison table
rmse_comparison = data.frame (
  Model = c("CART","Random Forest","Gradient-Boosted Tree"),
  RMSE = c(rmse_cart, rmse_rf,rmse_gbm)
)

kable(rmse_comparison)

```

```{r problem 4ggmap, message=FALSE, echo=FALSE, warning=FALSE}

#fetch a map of CA
bbox <- c(bottom = 32.213, top = 42.163 , right = -113.95, left = -124.585)
camap <- get_stamenmap(bbox = bbox, zoom = 9)

#Plot A: plot of the original data, using a color scale to show medianHouseValue (or log medianHouseValue) versus longitude (x) and latitude (y).
ggmap(camap) + geom_point(data = cahousing, aes(x = longitude, y = latitude, color = medianHouseValue)) + scale_color_continuous() + labs(title="Median House Value from the Original Data", x="Longitude" , y ="Latitude")
                                              
#finding predictions of medianhouseValue and residuals using random forest model

medianhouseValue_pred = predict(cahousing.forest, cahousing)

cahousing$medianhouseValue_pred = medianhouseValue_pred
cahousing$resid = cahousing$medianhouseValue - medianhouseValue_pred


#Plot B: model's predictions of medianHouseValue (or log medianHouseValue) versus longitude (x) and latitude (y).

ggmap(camap) + geom_point(data = cahousing, aes(x = longitude, y = latitude, color = medianhouseValue_pred)) + scale_color_continuous() + labs(title="Prediction of Median House Value ", x="Longitude" , y ="Latitude")

#Plot C: model's errors/residuals (or log residuals) versus longitude (x) and latitude (y).

ggmap(camap) + geom_point(data = cahousing, aes(x = longitude, y = latitude, color = resid)) + scale_color_continuous() + labs(title="Model's Residuals", x="Longitude" , y ="Latitude")

```