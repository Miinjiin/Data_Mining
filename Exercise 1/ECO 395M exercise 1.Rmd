---
title: "ECO 395 Homework 1"
author: "Minjin Kang, Paul Park"
date: "2023-01-21"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(rsample)
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(dplyr)

```

## 1) Data visualization: flights at ABIA



**Question: What is the best time of year to fly to minimize delays, and does this change by destination?**



```{r problem 1a, message=FALSE, echo=FALSE, warning=FALSE}
# read in the data: make sure to use the path name to
# wherever you'd stored the file
ABIA = read.csv('Data/ABIA.csv')

# Filter rows with origin = AUS
ABIA_austin_origin = ABIA %>%
  filter(Origin == "AUS")

# Create a new column from two existing columns
ABIA_augmented = ABIA_austin_origin %>%
  mutate(TotalDelay = ArrDelay + DepDelay)

# Replace N/A values with zeros 
ABIA_augmented[is.na(ABIA_augmented)] = 0

# Monthly average delay
ABIA_monthlytotal <- ABIA_augmented %>%
  group_by(Month) %>%
  summarise(Mean_Delay= mean(TotalDelay))

# Plot monthly aggregate average delay
ggplot(ABIA_monthlytotal) + 
  geom_line(aes(x=Month, y=Mean_Delay), size=1.1) +
  labs(x="Month",
       y="Average Delays (in minute)",
       title="Monthly Average Delay for All Flights Departing AUS",
       subtitle="(Year 2008)") + 
  scale_x_continuous(breaks = seq(1, 12, by = 1)) + 
  theme_bw() +
  theme(plot.title = element_text(face="bold"))
```


**Figure 1:** Line graph showing monthly average delay time for 49,623 flights that departed from AUS in 2008.

Figure 1 shows that the best months to fly from Austin to minimize delays are September and October. September has the least delays of all (around two minutes), while October has an average delay of four minutes, which is significantly less compared to other months. This makes sense as these months lie between the two busiest travel seasons of the year, summer vacation (July and August) and Thanksgiving and Christmas/New Year (November and December)


```{r problem 1b, message=FALSE, echo=FALSE}
# Second, we will see if this monthly aggregate average delay trend is changing by destination. We choose six popular destination.

# Pick top 6 destination by counting rows by each destination
top_six_dest <- ABIA_augmented %>%
  count(Dest, sort = TRUE)

# Make data containing only top 6 destination
top6_dest <- subset(ABIA_augmented, Dest == "DAL" | Dest == "DFW" | Dest == "IAH" | Dest == "PHX" | Dest == "DEN" | Dest == "ORD")

# Monthly average delay for each Destination
top6_dest_groupby <- top6_dest%>%
  group_by(Month,Dest) %>%
  summarise(MeanDelay=mean(TotalDelay))

# Make dataframe 
df <- top6_dest_groupby %>% as.data.frame()

# Plot top 6 destination monthly average delay
ggplot(df, aes(x=Month, y=MeanDelay, shape=Dest,color=Dest)) +
  geom_line() +
  labs(x="Month",
       y="Average Delays (in minute)",
       title="Monthly Average Delay for Flights Departing AUS by Destination",
       subtitle="(Year 2008)") + 
  scale_x_continuous(breaks = seq(1, 12, by = 1)) + 
  theme_bw() +
  theme(plot.title = element_text(face="bold"))
```


**Figure 2:** Line graph showing monthly average delay time for 22,740 flights that departed from AUS to the six most popular destination airports in 2008.

Next, we wanted to find out whether the result changes by destination. We picked six most popular destinations, which are Dallas Love Field Airport (DAL), Denver International Airport (DEN), Dallas/Fort Worth International Airport (DFW), George Bush Intercontinental Airport (IAH), Chicago O'Hare International Airport (ORD), Phoenix Sky Harbor International Airport (PHX). Figure 2 shows that the overall trend of delays throughout the year is similar to that shown by Figure 1. In general, September and October seem to be the months with the least flight delays.



## 2) Wrangling the Olympics

#### A) What is 95th percentile of heights for female competitiors across Athletics events?
```{r problem 2A, message=FALSE, echo=FALSE}

# read in the data: make sure to use the path name to
# wherever you'd stored the file
Olympics = read.csv('Data/olympics_top20.csv')

# Filter to get female and Athletics data only
Olympics_female=Olympics %>%
  filter(sex=="F", sport=="Athletics")

# Get 95th percentile of heights
Output = quantile(Olympics_female$height, 0.95)

Numquantile="95%"

df1<- data.frame(Numquantile,Output, row.names = "")

knitr::kable(head(df1, 1), col.names = c("quantile", "height"))
```

95th percentile of heights for female competitors across Athletcis events is 183cm.

#### B) Which single women's event had the greatest variability in competitor's heights across the entire history of the Olympics, as measured by the standard deviation?
```{r problem 2B, message=FALSE, echo=FALSE}

# Filter to get female data, group by event and getting standard deviation for each event. Slicing to get event having the highest standard deviation. 
Olympics_female_event = Olympics %>%
  filter(sex=="F") %>%
  group_by(event) %>%
  summarise(heightvariance=sd(height)) %>%
  slice(which.max(heightvariance)) %>% as.data.frame()

# Make dataframe 
df_f <- Olympics_female_event%>% as.data.frame()

knitr::kable(head(df_f, 1), col.names = c("Event", "Height Variability"))

```

Rowing Womenâ€™s Coxed Fours has the greatest variability in women competitor's heights across the entire history of the Olympics.

#### C) How has the average age of Olympic swimmers changed over time? Does this trend look different depending on the gender?
```{r problem 2C, message=FALSE, echo=FALSE}

# Filter to get swimmer data, group by gender to see if the trend look different depending on gender, and group by year to see trend of the data and export to dataframe to visualize
Olympics_swimmerage = Olympics %>%
  filter(sport=="Swimming") %>%
  group_by(sex,year) %>%
  summarise(Meanage=mean(age)) %>% as.data.frame()

# Plot the data with line graph
ggplot(Olympics_swimmerage,aes(x=year, y=Meanage,color=sex))+
  geom_line() + geom_point() +
  labs(title="Change in Average Age for Male and Female Swimmers",
       
       x="Year",
       y="Average age") +
       #subtitle="(Year 1896 Olympic Medalist)") +
  theme_classic() +
  theme(plot.title = element_text(face="bold"))


```

**Figure 3:** Line graph showing the change in average age of Olympic swimmers between 1600 - 2016

The change in average age has an overall upward trend for both male and female Olympic swimmers. For male swimmers, the average age marks its lowest (mid-teens) in the early 1900's and goes through a period of steep hike through 1925. It then rapidly comes back down to late teens/early twenties and steadily increases over a long period of time. By 2000, the average male swimmer's age is approximately mid-twenties. The female swimmer's average age displays a somewhat similar of an upward trend. The average age revolves around early to mid teens between 1925 and 1975, then we see a massive spike that moves the average age towards early to mid twenties through 2000s. Average age of female swimmers is certainly lower than that of male swimmers throughout history, but the rising trend is congruent.




## 3) K-nearest neighbors: cars

### Car trim level 350

```{r problem 3_1.1, message=FALSE, echo=FALSE}
sclass = read.csv('Data/sclass.csv')

# Filter for trim level :350
sclass_350 <- sclass %>%
  filter(trim=='350')

# Requirement 1 : Do a train-test split for car with trim 350 with ratio 80:20
sclass350_split =  initial_split(sclass_350, prop=0.8)
sclass350_train = training(sclass350_split)
sclass350_test  = testing(sclass350_split)

# Requirement 2,3 : Running KNN with multiple K >= 2 and for each value of K, and fit the model, getting RMSE for each value of K
k_grid=2:150

# Using the code in 02_intro_learning slide, run RNN and check RMSE value for k value from 2 to 150
rmse_350_out = foreach(i=2:150, .combine='c') %do% {
  knn_350=knnreg(price ~ mileage, data=sclass350_train, k=i)
  rmse(knn_350, sclass350_test)
}
# Make a data frame for plotting
rmse_350_df <- rmse_350_out %>% as.data.frame()



# Plotting 
# Set x-axis for k, set y-axis for RMSE and plotting to find k value which has the lowest RMSE
ggplot(rmse_350_df, aes(x = k_grid, y = rmse_350_out)) +
  geom_line(color="blue") +
  labs(x="K",
       y="RMSE",
       title="Plot for Root Mean Squared Error(RMSE) to find the optimal K value",
       subtitle="(Sclass trim 350)") +
  theme_minimal() +
  theme(plot.title = element_text(face="bold"))

```


**Figure 1:** Plot showing RMSE for each value of K (from 2 to 150)

Here, we can see which K value has the lowest RMSE, and this is the optimal value of K


**Optimal value of K**

```{r problem 3_1.2, message=FALSE, echo=FALSE}

# Find the optimal value of K 
k_grid[which.min(rmse_350_out)]

```

**RMSE from the Optimal value of K**

```{r problem 3_1.3, message=FALSE, echo=FALSE}

# KNN with the optimal value K and getting RMSE
knn_350=knnreg(price ~ mileage, data=sclass350_train, k=k_grid[which.min(rmse_350_out)])
rmse(knn_350,sclass350_test)

```


```{r problem 3_1.4, message=FALSE, echo=FALSE}

# Attach the predictions to the test data frame
sclass350_test = sclass350_test %>%
  mutate(price_pred = predict(knn_350, sclass350_test))

p_test = ggplot(data = sclass350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.5) +
  ggtitle("Predictions of price given mileage")


# now add the predictions
p_test + 
  geom_line(aes(x = mileage, y = price_pred), color='firebrick', size=1.5) +
  theme_minimal() +
  theme(plot.title = element_text(face="bold"))


```

**Figure 2:** Plot of the fitted model, predicted price and real price






### Car trim level 65 AMG

```{r problem 3_2.1, message=FALSE, echo=FALSE}

# Filter for trim level :65 AMG
sclass_65 <- sclass %>%
  filter(trim=='65 AMG')


# Requirement 1 : Do a train-test split for car with trim 65 AMG with ratio 80:20
sclass65_split =  initial_split(sclass_65, prop=0.8)
sclass65_train = training(sclass65_split)
sclass65_test  = testing(sclass65_split)


# Requirement 2,3 : Running KNN with multiple K >= 2 and for each value of K, and fit the model, getting RMSE for each value of K
k_grid=2:150
# Using the code in 02_intro_learning slide, run RNN and check RMSE value for k value from 2 to 150
rmse_65_out = foreach(i=2:150, .combine='c') %do% {
  knn_65=knnreg(price ~ mileage, data=sclass65_train, k=i)
  rmse(knn_65, sclass65_test)
}
# Make a data frame for plotting
rmse_65_df <- rmse_65_out %>% as.data.frame()

# Plotting 
# Set x-axis for k, set y-axis for RMSE and plotting to find k value which has the lowest RMSE
ggplot(rmse_65_df, aes(x = k_grid, y = rmse_65_out)) +
  geom_line(color="blue") +
  labs(x="K",
       y="RMSE",
       title="Plot for Root Mean Squared Error(RMSE) to find the optimal K value",
       subtitle="(Sclass trim 65 AMG)") +
       theme_minimal() +
         theme(plot.title = element_text(face="bold"))

```


**Figure 3:** Plot showing RMSE for each value of K (from 2 to 150)

Here, we can see which K value has the lowest RMSE, and this is the optimal value of K


**Optimal value of K**

```{r problem 3_2.2, message=FALSE, echo=FALSE}

# Find the optimal value of K 
k_grid[which.min(rmse_65_out)]

```


**RMSE from the Optimal value of K**

```{r problem 3_2.3, message=FALSE, echo=FALSE}

# KNN with the optimal value of K and getting RMSE
knn_65=knnreg(price ~ mileage, data=sclass65_train, k=k_grid[which.min(rmse_65_out)])
rmse(knn_65,sclass65_test)


```


```{r problem 3_2.4, message=FALSE, echo=FALSE}

# Attach the predictions to the test data frame
sclass65_test = sclass65_test %>%
  mutate(price_pred = predict(knn_65, sclass65_test))

p_test = ggplot(data = sclass65_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.5) +
  ggtitle("Predictions of price given mileage")


# Now add the predictions
p_test + 
  geom_line(aes(x = mileage, y = price_pred), color='firebrick', size=1.5) +
  theme_minimal() +
  theme(plot.title = element_text(face="bold"))


```

**Figure 4:** Plot of the fitted model, predicted price and real price


**Result: Trim 350 yields a larger optimal value of K**
```{r problem 3_3, message=FALSE, echo=FALSE}


Trim_350_row=length(which(sclass$trim=="350"))
Trim_65_row=length(which(sclass$trim=="65 AMG"))

df<- data.frame(Trim_350_row,Trim_65_row, row.names = "Number of rows")

knitr::kable(head(df, 1), col.names = c("Trim 350", "Trim 65 AMG"))
```

Trim 350 has larger optimal K value as it contains more data points than trim 65 AMG. 
More data points means lower variance, less chance of memorizing random noise. 
